"""
Single-file Telegram bot: Raw text (.txt or pasted) â†’ 1-minute vertical video short (voice-over + slides)

- Paste your @BotFather token below (BOT_TOKEN).
- DistilBART summarizer by default; switch to BART-Large with /model bart.
- gTTS voice; change accent via /voice us|uk|in.
- MoviePy v2 with imageio-ffmpeg, no apt needed.
- Long polling; Colab-friendly.

Commands:
  /start                  Help
  /model distilbart|bart  Switch summarizer
  /voice us|uk|in         Accent (us=default)
"""

# =========================  USER: PASTE YOUR TOKEN HERE  =========================
BOT_TOKEN = "PASTE_YOUR_TELEGRAM_BOT_TOKEN_HERE"
# ================================================================================

# --------------------- Safe auto-install (maps import names) --------------------
import sys, subprocess, importlib

def pip_install(spec: str):
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", spec])

# (pip_name, import_name)
REQUIRED = [
    ("python-telegram-bot==22.3", "telegram"),
    ("gTTS==2.5.4", "gtts"),
    ("moviepy==2.2.1", "moviepy"),
    ("transformers==4.45.2", "transformers"),
    ("sentencepiece==0.2.0", "sentencepiece"),
    ("accelerate==0.34.2", "accelerate"),
    ("pillow==10.4.0", "PIL"),
    ("imageio-ffmpeg>=0.4.9", "imageio_ffmpeg"),
]

for pip_name, import_name in REQUIRED:
    try:
        importlib.import_module(import_name)
    except Exception:
        pip_install(pip_name)

# ------------------------------- Imports (clean) --------------------------------
import io, re, uuid, tempfile, os
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageFilter

import imageio_ffmpeg
os.environ["IMAGEIO_FFMPEG_EXE"] = imageio_ffmpeg.get_ffmpeg_exe()

import torch
from transformers import pipeline

# MoviePy v2 preferred imports (fallback to v1 editor only if needed)
try:
    from moviepy import (
        ImageClip, AudioFileClip,
        concatenate_audioclips, concatenate_videoclips
    )
except Exception:
    from moviepy.editor import (
        ImageClip, AudioFileClip,
        concatenate_audioclips, concatenate_videoclips
    )

# Try v2 audio fx; if missing, provide a robust fallback
try:
    from moviepy.audio.fx import audio_speedx as _audio_speedx
    _HAS_AUDIO_SPEEDX = True
except Exception:
    _HAS_AUDIO_SPEEDX = False
    from moviepy.audio.AudioClip import AudioClip
    def _audio_speedx(clip, factor: float):
        """Fallback time-remap for audio: out(t) = in(t*factor)"""
        fps = getattr(clip, "fps", 44100)
        def make_frame(t):
            t_in = t * factor
            if t_in >= clip.duration:
                arr0 = clip.get_frame(0)
                return np.zeros_like(arr0)
            return clip.get_frame(t_in)
        return AudioClip(make_frame, duration=(clip.duration / factor), fps=fps)

from gtts import gTTS

from telegram import Update
from telegram.constants import ChatAction
from telegram.ext import (
    ApplicationBuilder, MessageHandler, CommandHandler,
    ContextTypes, filters
)

# ---------------------------- Global configuration ------------------------------
assert BOT_TOKEN and ":" in BOT_TOKEN, "â— Please paste a valid Telegram bot token at the top."

DEVICE = 0 if torch.cuda.is_available() else -1
SUMM_MODEL = "sshleifer/distilbart-cnn-12-6"  # switch via /model to 'facebook/bart-large-cnn'
TARGET_MAX_SECONDS = 60.0
SAFE_MARGIN = 0.90                 # aim a bit under 60s
CANVAS = (720, 1280)               # vertical 9:16
DEFAULT_FONT = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
CURRENT_TLD = "com"                # gTTS accent: 'com' (US), 'co.uk' (UK), 'co.in' (India)

# Build summarizer pipeline
summarizer = pipeline("summarization", model=SUMM_MODEL, device=DEVICE)

# ------------------------------- Small utilities --------------------------------
def clean_text(s: str) -> str:
    return re.sub(r"\s+", " ", s or "").strip()

def infer_title_from_text(text: str) -> str:
    """
    First non-empty line (<=120 chars, >=3 words) else first 3-20 word sentence; else 'Update'.
    """
    if not text:
        return "Update"
    for ln in text.splitlines():
        ln = ln.strip()
        if ln and len(ln) <= 120 and len(ln.split()) >= 3:
            return ln
    for seg in re.split(r'(?<=[.!?])\s+', clean_text(text)):
        if 3 <= len(seg.split()) <= 20:
            return seg
    return "Update"

# -------------------------------- Summarization ---------------------------------
def summarize_to_segments(title: str, text: str, max_words: int = 140):
    """
    Produce a shorts-style script: Hook â†’ up to 3 points â†’ Wrap (<= ~140 words).
    """
    text = clean_text(text)
    if not text or len(text.split()) < 30:
        text = (text + " " + text) if text else "No content provided."

    chunks = [text[i:i+4000] for i in range(0, len(text), 4000)] if len(text) > 4000 else [text]
    outs = []
    for ch in chunks:
        out = summarizer(ch, max_length=150, min_length=60, do_sample=False)[0]["summary_text"]
        outs.append(clean_text(out))
    summary = clean_text(" ".join(outs))

    hook = clean_text(title) if title else "Hereâ€™s the quick update:"
    sentences = [s.strip() for s in re.split(r'(?<=[.!?])\s+', summary) if len(s.split()) > 4]
    bullets = sentences[:3] if sentences else [summary]
    wrap = "Thatâ€™s the story in 60 seconds. Follow for more."

    pieces = [hook] + bullets[:3] + [wrap]
    words = " ".join(pieces).split()
    if len(words) > max_words:
        words = words[:max_words]
    full = " ".join(words)

    segments = []
    if full.startswith(hook):
        segments.append(("Hook", hook))
        rest = full[len(hook):].strip()
    else:
        rest = full
    pts = [s.strip() for s in re.split(r'(?<=[.!?])\s+', rest) if s.strip()]
    for i, seg in enumerate(pts[:3]):
        segments.append((f"Point {i+1}", seg))
    segments.append(("Wrap", wrap))
    return segments

# ------------------------------- Slide rendering --------------------------------
def _wrap_text(draw, text, font, max_w):
    words, lines, cur = text.split(), [], []
    for w in words:
        trial = " ".join(cur + [w])
        w_px = draw.textbbox((0,0), trial, font=font)[2]
        if w_px <= max_w:
            cur.append(w)
        else:
            lines.append(" ".join(cur)); cur=[w]
    if cur: lines.append(" ".join(cur))
    return lines

def make_slide_png(text, size=CANVAS, pad=48, font_size=44, bg_color=(18,18,22)):
    W,H = size
    im = Image.new("RGB", size, bg_color)
    overlay = Image.new("RGBA", size, (0,0,0,140))
    im = Image.alpha_composite(im.convert("RGBA"), overlay).convert("RGB")

    draw = ImageDraw.Draw(im)
    try:
        font = ImageFont.truetype(DEFAULT_FONT, font_size)
    except Exception:
        font = ImageFont.load_default()

    max_w = W - 2*pad
    lines = _wrap_text(draw, text, font, max_w)
    total_h = sum(draw.textbbox((0,0), ln, font=font)[3] for ln in lines) + (len(lines)-1)*8
    y = (H - total_h)//2
    for ln in lines:
        w_px, h_px = draw.textbbox((0,0), ln, font=font)[2:]
        x = (W - w_px)//2
        draw.text((x,y), ln, fill=(255,255,255), font=font)
        y += h_px + 8

    buf = io.BytesIO()
    im.save(buf, format="PNG")
    return buf.getvalue()

def png_bytes_to_clip(png_bytes, duration):
    im = Image.open(io.BytesIO(png_bytes)).convert("RGB")
    frame = np.array(im)
    return ImageClip(frame).set_duration(duration)

# ----------------------------- TTS + video compose ------------------------------
def tts_to_mp3(text, lang="en", tld="com"):
    tts = gTTS(text=text, lang=lang, tld=tld, slow=False)
    tmp = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False)
    tts.save(tmp.name)
    return tmp.name

def build_video(segments, out_path="short.mp4",
                target_seconds=TARGET_MAX_SECONDS, tld="com"):
    # 1) Build audio per segment
    audio_clips, durs, tmp_files = [], [], []
    for _, text in segments:
        mp3 = tts_to_mp3(text, tld=tld)
        tmp_files.append(mp3)
        ac = AudioFileClip(mp3)
        audio_clips.append(ac)
        durs.append(ac.duration)

    # 2) Time fit within ~60s (slight speed-up if needed)
    total = sum(durs)
    if total > target_seconds * SAFE_MARGIN:
        factor = total / (target_seconds * SAFE_MARGIN)  # >1 â†’ speed up
        audio_clips = [_audio_speedx(ac, factor) for ac in audio_clips]
        durs = [ac.duration for ac in audio_clips]

    # 3) Slides to match durations
    slides = []
    for (_, text), dur in zip(segments, durs):
        png = make_slide_png(text, size=CANVAS)
        slides.append(png_bytes_to_clip(png, dur))

    video = concatenate_videoclips(slides, method="compose")
    voice = concatenate_audioclips(audio_clips)
    video = video.set_audio(voice)

    # 4) Export with modest bitrates (stay well under Telegram ~50MB limit)
    video.write_videofile(
        out_path, fps=30, codec="libx264", audio_codec="aac",
        bitrate="1200k", audio_bitrate="128k",
        threads=2, preset="medium", verbose=False, logger=None
    )

    # Cleanup temp mp3s
    try:
        for ac in audio_clips: ac.close()
        for f in tmp_files:
            if os.path.exists(f): os.unlink(f)
    except Exception:
        pass
    return out_path
# -------------------------------- Telegram bot ----------------------------------
HELP_TEXT = (
    "Send me your article **text** and Iâ€™ll return a â‰ˆ1â€‘minute vertical short "
    "with voiceâ€‘over and key points.\n\n"
    "Ways to send text:\n"
    "â€¢ Paste directly in chat (up to ~4,000 characters)\n"
    "â€¢ For longer text, attach a **.txt** file (plain text)\n\n"
    "Commands:\n"
    "/start â€“ help\n"
    "/model distilbart|bart â€“ choose summarizer (distilbart is faster)\n"
    "/voice us|uk|in â€“ choose accent (us=default)\n"
)

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(HELP_TEXT, disable_web_page_preview=True)

async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global summarizer, SUMM_MODEL
    parts = update.message.text.split()
    if len(parts) < 2:
        await update.message.reply_text("Use: /model distilbart  or  /model bart")
        return
    choice = parts[1].lower()
    SUMM_MODEL = "sshleifer/distilbart-cnn-12-6" if choice.startswith("distil") else "facebook/bart-large-cnn"
    await update.message.reply_text(f"Switching to {SUMM_MODEL}â€¦ (first use may download the model)")
    device = 0 if torch.cuda.is_available() else -1
    summarizer = pipeline("summarization", model=SUMM_MODEL, device=device)
    await update.message.reply_text("Model ready âœ“")

async def cmd_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global CURRENT_TLD
    parts = update.message.text.split()
    if len(parts) < 2:
        await update.message.reply_text("Use: /voice us|uk|in")
        return
    CURRENT_TLD = {"uk":"co.uk","in":"co.in"}.get(parts[1].lower(), "com")
    await update.message.reply_text(f"Voice accent set âœ“ (tld={CURRENT_TLD})")

async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    raw = (update.message.text or "").strip()
    if not raw:
        await update.message.reply_text("Please paste the article text, or send a .txt file.")
        return
    await context.bot.send_chat_action(update.effective_chat.id, ChatAction.TYPING)
    try:
        title = infer_title_from_text(raw)
        segments = summarize_to_segments(title, raw, max_words=140)

        await update.message.reply_text("Creating your 1â€‘minute shortâ€¦ This may take ~1â€“3 minutes.")
        await context.bot.send_chat_action(update.effective_chat.id, ChatAction.UPLOAD_VIDEO)

        out_file = f"./short_{uuid.uuid4().hex[:8]}.mp4"
        video_path = build_video(segments, out_path=out_file,
                                 target_seconds=TARGET_MAX_SECONDS, tld=CURRENT_TLD)

        with open(video_path, "rb") as vf:
            await update.message.reply_video(
                video=vf, width=CANVAS[0], height=CANVAS[1],
                caption="Your short is ready! ðŸŽ¬"
            )
    except Exception as e:
        await update.message.reply_text(f"Sorry, I couldn't process that. Error: {e!s}")

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    doc = update.message.document
    if not doc:
        await update.message.reply_text("Please send a .txt file or paste your text.")
        return
    is_txt = (doc.mime_type == "text/plain") or (doc.file_name or "").lower().endswith(".txt")
    if not is_txt:
        await update.message.reply_text("Please send a plain text (.txt) file.")
        return

    await context.bot.send_chat_action(update.effective_chat.id, ChatAction.TYPING)
    try:
        file = await context.bot.get_file(doc.file_id)
        bio = io.BytesIO()
        await file.download_to_memory(out=bio)
        data = bio.getvalue()

        raw = None
        for enc in ("utf-8", "utf-16", "cp1252", "latin-1"):
            try:
                raw = data.decode(enc)
                break
            except Exception:
                pass
        if not raw or not raw.strip():
            await update.message.reply_text("Could not read the file. Please save as UTFâ€‘8 and resend.")
            return
        raw = raw.strip()
        title = infer_title_from_text(raw)
        segments = summarize_to_segments(title, raw, max_words=140)

        await update.message.reply_text("Creating your 1â€‘minute shortâ€¦ This may take ~1â€“3 minutes.")
        await context.bot.send_chat_action(update.effective_chat.id, ChatAction.UPLOAD_VIDEO)

        out_file = f"./short_{uuid.uuid4().hex[:8]}.mp4"
        video_path = build_video(segments, out_path=out_file,
                                 target_seconds=TARGET_MAX_SECONDS, tld=CURRENT_TLD)

        with open(video_path, "rb") as vf:
            await update.message.reply_video(
                video=vf, width=CANVAS[0], height=CANVAS[1],
                caption="Your short is ready! ðŸŽ¬"
            )
    except Exception as e:
        await update.message.reply_text(f"Sorry, I couldn't process that. Error: {e!s}")

def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("voice", cmd_voice))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))
    app.run_polling()

if __name__ == "__main__":
    # Small environment print (helps debug if anything fails)
    import moviepy, platform
    print("MoviePy:", moviepy.__version__,
          "| CUDA:", torch.cuda.is_available(),
          "| Python:", sys.version.split()[0],
          "| OS:", platform.system())
    print("ffmpeg:", os.popen(f'"{imageio_ffmpeg.get_ffmpeg_exe()}" -version').read().splitlines()[0])
    print("Starting botâ€¦ (Interrupt the cell to stop)")
    main()
