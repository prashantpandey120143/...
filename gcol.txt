%pip -q install --upgrade \
  python-telegram-bot==22.3 \
  trafilatura==2.0.0 \
  newspaper3k==0.2.8 \
  gTTS==2.5.4 \
  moviepy==2.2.1 \
  transformers==4.45.2 \
  sentencepiece==0.2.0 \
  accelerate==0.34.2 \
  pillow==10.4.0 \
  imageio-ffmpeg>=0.4.9

!apt -yqq install ffmpeg > /dev/null

import moviepy, sys, torch, platform, subprocess
print("MoviePy:", moviepy.__version__)
print("PyTorch CUDA:", torch.cuda.is_available(), "; device:", "cuda" if torch.cuda.is_available() else "cpu")
print("Python:", sys.version.split()[0], "|", platform.system())
!ffmpeg -version | head -n 1



#@title â† Paste your Telegram Bot Token here and run this cell
BOT_TOKEN = ""  # @param {type:"string"}
import os
assert BOT_TOKEN, "Please paste your token above, then run this cell."
os.environ["TELEGRAM_BOT_TOKEN"] = BOT_TOKEN.strip()
print("Token saved âœ“")




import os, io, re, json, math, tempfile, uuid, textwrap
from urllib.parse import urlparse
from datetime import datetime

import requests
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import numpy as np

# Article extraction
from trafilatura import fetch_url, extract as trafi_extract
from newspaper import Article as NPArticle

# Summarization
import torch
from transformers import pipeline

# Movie generation (MoviePy v2-friendly imports)
try:
    from moviepy import (
        ImageClip, AudioFileClip, CompositeAudioClip,
        concatenate_audioclips, concatenate_videoclips
    )
except Exception:
    # fallback (older MoviePy v1)
    from moviepy.editor import (
        ImageClip, AudioFileClip, CompositeAudioClip,
        concatenate_audioclips, concatenate_videoclips
    )
from moviepy.audio.fx.all import audio_speedx

# Telegram bot
from telegram import Update
from telegram.constants import ChatAction
from telegram.ext import ApplicationBuilder, MessageHandler, CommandHandler, ContextTypes, filters

# ---------- GLOBAL CONFIG ----------
DEVICE = 0 if torch.cuda.is_available() else -1
SUMM_MODEL = "sshleifer/distilbart-cnn-12-6"  # fast default (switchable to 'facebook/bart-large-cnn')
TARGET_MAX_SECONDS = 60.0
SAFE_MARGIN = 0.90
CANVAS = (720, 1280)  # Vertical 9:16
DEFAULT_FONT = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"





# ------------------- Extraction -------------------

def extract_with_trafilatura(url: str):
    downloaded = fetch_url(url)
    if not downloaded:
        return None
    data = trafi_extract(downloaded, output_format="json", with_metadata=True, include_comments=False)
    if not data:
        return None
    obj = json.loads(data)
    top_image = None
    if "images" in obj and obj["images"]:
        candidates = [im.get("src") for im in obj["images"] if isinstance(im, dict) and "src" in im]
        top_image = candidates[0] if candidates else None
    return {
        "title": obj.get("title"),
        "text": obj.get("text") or obj.get("raw_text"),
        "date": obj.get("date"),
        "site": obj.get("sitename") or urlparse(url).netloc,
        "top_image": top_image
    }

def extract_with_newspaper(url: str):
    try:
        art = NPArticle(url=url, language="en")
        art.download(); art.parse()
        try: art.nlp()
        except Exception: pass
        return {
            "title": art.title or "News Update",
            "text": art.text,
            "date": str(art.publish_date) if art.publish_date else None,
            "site": urlparse(url).netloc,
            "top_image": getattr(art, "top_image", None) or None
        }
    except Exception:
        return None

def extract_article(url: str):
    data = extract_with_trafilatura(url)
    if not data or not data.get("text"):
        data = extract_with_newspaper(url)
    if not data or not data.get("text"):
        raise ValueError("Could not extract main article content (may be paywalled or blocked).")
    return data

# ------------------- Summarization -------------------

def clean_text(s: str):
    return re.sub(r"\s+", " ", s or "").strip()

# Build summarizer once (cached by HF)
summarizer = pipeline("summarization", model=SUMM_MODEL, device=DEVICE)

def summarize_to_segments(title: str, text: str, site: str, max_words: int = 140):
    text = clean_text(text)
    # Chunk very long text for better summarization stability
    chunks = [text[i:i+4000] for i in range(0, len(text), 4000)] if len(text) > 4000 else [text]
    partials = []
    for ch in chunks:
        out = summarizer(ch, max_length=150, min_length=60, do_sample=False)[0]["summary_text"]
        partials.append(clean_text(out))
    summary = clean_text(" ".join(partials))

    # Shorts script shape: Hook â†’ 3 points â†’ Wrap
    hook = clean_text(title) if title else "Hereâ€™s the quick update:"
    # Split into sentences and take up to 3 good ones
    sentences = [s.strip() for s in re.split(r'(?<=[.!?])\s+', summary) if len(s.split()) > 4]
    bullets = sentences[:3] if sentences else [summary]

    wrap = "Thatâ€™s the story in 60 seconds. Follow for more."
    src = f"(Source: {site})" if site else ""

    pieces = [hook] + bullets[:3] + [wrap]
    # Enforce word budget
    words = " ".join(pieces).split()
    if len(words) > max_words:
        words = words[:max_words]
    final_text = " ".join(words)

    # Re-split into segments (heuristic)
    segments = []
    # Hook
    if final_text.startswith(hook):
        segments.append(("Hook", hook))
        rest = final_text[len(hook):].strip()
    else:
        rest = final_text

    # Try to carve out up to 3 sentences for points
    pts = [s.strip() for s in re.split(r'(?<=[.!?])\s+', rest) if s.strip()]
    for i, seg in enumerate(pts[:3]):
        segments.append((f"Point {i+1}", seg))

    # Wrap (ensure source tag visible)
    last = wrap + (" " + src if src else "")
    segments.append(("Wrap", last))
    return segments

# ------------------- Slides (PIL) -------------------

def wrap_text(draw, text, font, max_w):
    words, lines, cur = text.split(), [], []
    for w in words:
        trial = " ".join(cur + [w])
        w_px = draw.textbbox((0,0), trial, font=font)[2]
        if w_px <= max_w:
            cur.append(w)
        else:
            lines.append(" ".join(cur)); cur=[w]
    if cur: lines.append(" ".join(cur))
    return lines

def make_slide_png(text, bg_image=None, size=CANVAS, pad=48, font_size=44, bg_color=(18,18,22)):
    W,H = size
    if bg_image:
        try:
            r = requests.get(bg_image, timeout=10)
            im = Image.open(io.BytesIO(r.content)).convert("RGB")
            im = im.resize(size).filter(ImageFilter.GaussianBlur(2))
        except Exception:
            im = Image.new("RGB", size, bg_color)
    else:
        im = Image.new("RGB", size, bg_color)

    overlay = Image.new("RGBA", size, (0,0,0,140))
    im = Image.alpha_composite(im.convert("RGBA"), overlay).convert("RGB")

    draw = ImageDraw.Draw(im)
    try:
        font = ImageFont.truetype(DEFAULT_FONT, font_size)
    except Exception:
        font = ImageFont.load_default()

    max_w = W - 2*pad
    lines = wrap_text(draw, text, font, max_w)
    total_h = sum(draw.textbbox((0,0), ln, font=font)[3] for ln in lines) + (len(lines)-1)*8
    y = (H - total_h)//2
    for ln in lines:
        bbox = draw.textbbox((0,0), ln, font=font)
        w_px, h_px = bbox[2], bbox[3]
        x = (W - w_px)//2
        draw.text((x,y), ln, fill=(255,255,255), font=font)
        y += h_px + 8

    buf = io.BytesIO()
    im.save(buf, format="PNG")
    return buf.getvalue()

def png_bytes_to_clip(png_bytes, duration):
    im = Image.open(io.BytesIO(png_bytes)).convert("RGB")
    frame = np.array(im)
    return ImageClip(frame).set_duration(duration)

# ------------------- TTS + Video -------------------

from gtts import gTTS

def tts_to_mp3(text, lang="en", tld="com"):
    tts = gTTS(text=text, lang=lang, tld=tld, slow=False)
    tmp = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False)
    tts.save(tmp.name)
    return tmp.name

def build_video(segments, top_image=None, out_path="short.mp4", target_seconds=TARGET_MAX_SECONDS,
                tld="com"):
    # 1) TTS for each segment
    audio_clips, durs, temp_files = [], [], []
    for label, text in segments:
        mp3 = tts_to_mp3(text, tld=tld)
        temp_files.append(mp3)
        ac = AudioFileClip(mp3)
        audio_clips.append(ac)
        durs.append(ac.duration)

    total = sum(durs)
    speed_factor = 1.0
    if total > target_seconds * SAFE_MARGIN:
        speed_factor = total / (target_seconds * SAFE_MARGIN)
        audio_clips = [audio_speedx(ac, speed_factor) for ac in audio_clips]
        durs = [ac.duration for ac in audio_clips]

    # 2) Slides aligned to audio durations
    slide_clips = []
    for (label, text), dur in zip(segments, durs):
        png = make_slide_png(text, bg_image=top_image, size=CANVAS)
        slide_clips.append(png_bytes_to_clip(png, dur))

    video = concatenate_videoclips(slide_clips, method="compose")
    voice = concatenate_audioclips(audio_clips)
    video = video.set_audio(voice)

    # 3) Export: keep bitrate modest to fit Telegram 50MB limit
    video.write_videofile(
        out_path,
        fps=30,
        codec="libx264",
        audio_codec="aac",
        bitrate="1200k",
        audio_bitrate="128k",
        threads=2,
        preset="medium",
        verbose=False,
        logger=None
    )

    # Cleanup audio temps
    try:
        for ac in audio_clips: ac.close()
        for f in temp_files:
            if os.path.exists(f): os.unlink(f)
    except Exception:
        pass

    return out_path




BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
assert BOT_TOKEN, "Token missing â€” run Step 2."

HELP_TEXT = (
    "Send me a news/blog URL and Iâ€™ll return a 1â€‘minute vertical short "
    "with voiceâ€‘over and key points.\n\n"
    "Commands:\n"
    "/start â€“ help\n"
    "/model distilbart|bart â€“ choose summarizer (distilbart is faster)\n"
    "/voice us|uk|in â€“ choose accent (us=default)\n"
)

CURRENT_MODEL = SUMM_MODEL
CURRENT_TLD = "com"  # us accent by default; 'co.uk' for UK, 'co.in' for India

def is_url(s: str):
    try:
        u = urlparse(s.strip())
        return u.scheme in ("http","https") and u.netloc
    except Exception:
        return False

async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(HELP_TEXT)

async def cmd_model(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global summarizer, CURRENT_MODEL
    parts = update.message.text.split()
    if len(parts) < 2:
        await update.message.reply_text("Use: /model distilbart  or  /model bart")
        return
    choice = parts[1].lower()
    if choice.startswith("distil"):
        CURRENT_MODEL = "sshleifer/distilbart-cnn-12-6"
    elif choice.startswith("bart"):
        CURRENT_MODEL = "facebook/bart-large-cnn"
    else:
        await update.message.reply_text("Unknown model. Use: distilbart | bart")
        return
    await update.message.reply_text(f"Switching model to {CURRENT_MODEL}. Downloading (first time) â€¦")
    device = 0 if torch.cuda.is_available() else -1
    summarizer = pipeline("summarization", model=CURRENT_MODEL, device=device)
    await update.message.reply_text("Model ready âœ“")

async def cmd_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global CURRENT_TLD
    parts = update.message.text.split()
    if len(parts) < 2:
        await update.message.reply_text("Use: /voice us|uk|in")
        return
    v = parts[1].lower()
    if v == "uk": CURRENT_TLD = "co.uk"
    elif v == "in": CURRENT_TLD = "co.in"
    else: CURRENT_TLD = "com"
    await update.message.reply_text(f"Voice accent set âœ“ (tld={CURRENT_TLD})")

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = (update.message.text or "").strip()
    if not is_url(msg):
        await update.message.reply_text("Please send a valid http(s) URL.")
        return

    await context.bot.send_chat_action(update.effective_chat.id, ChatAction.TYPING)
    try:
        art = extract_article(msg)
        title = art.get("title") or "News Update"
        site  = art.get("site") or urlparse(msg).netloc
        text  = art["text"]
        top_image = art.get("top_image")

        segments = summarize_to_segments(title, text, site=site, max_words=140)

        await update.message.reply_text("Creating your 1â€‘minute shortâ€¦ This may take ~1â€“3 minutes initially.")
        await context.bot.send_chat_action(update.effective_chat.id, ChatAction.UPLOAD_VIDEO)

        out_file = f"/content/short_{uuid.uuid4().hex[:8]}.mp4"
        video_path = build_video(segments, top_image=top_image, out_path=out_file, target_seconds=TARGET_MAX_SECONDS,
                                 tld=CURRENT_TLD)

        await update.message.reply_video(
            video=open(video_path, "rb"),
            width=CANVAS[0], height=CANVAS[1],
            caption="Your short is ready! ðŸŽ¬"
        )
    except Exception as e:
        await update.message.reply_text(f"Sorry, I couldn't process that. Error: {e!s}")

async def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("model", cmd_model))
    app.add_handler(CommandHandler("voice", cmd_voice))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    await app.run_polling(close_loop=False)

import asyncio
asyncio.run(main())





